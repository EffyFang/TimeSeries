
---
title: "hw3"
author: "Kai Li"
date: "July 16, 2019"
output:
  pdf_document: default
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Time Series HW3

```{r message=FALSE}
# load libraries
library(caret)
library(TSA)
library(pls)
library(forecast)
library(tseries)
```


### Question 1 
Load the usgdp.rda dataset and split it into a training dataset (1947Q1 - 2005Q1) and a test dataset (2005Q2 - 2006Q1)

```{r}
# load the usgdp/rda data set
load("C:/Kai/UChicago/time_series/hw/usgdp.rda")


train = usgdp[1:(length(usgdp)-4)]
test = usgdp[(length(usgdp)-3):length(usgdp)]

train = ts(train, frequency = 4, start = c(1947, 1))
test  = ts(test , frequency = 4, start = c(2005, 2))

```


### Question 2:
Plot the training dataset. Is the Box-Cox transformation necessary for this data?
```{r}

plot.ts(train)


plot.ts(t_train)
```
The Box-Cox transformation is necessary for this data because the plot is increasing exponentially rather than linearly. To obtain a stationary time series data set Box-Cox transformation could help. 


###  Question 3:
Plot the 1st and 2nd order difference of the data. Apply KPSS Test for Stationarity to determine which difference order results in a stationary dataset.
```{r}
# get the lambda and tranform data by using Box-Cox method
lambda = BoxCox.lambda(train)
t_train = BoxCox(train, lambda = lambda)

# plot 1st order difference of the tranformed data
plot(diff(t_train))

# plot 2nd order difference of the tranformed data
plot(diff(diff(t_train)))


# KPSS test
kpss.test(t_train, null="Level")
kpss.test(diff(t_train), null="Level")
kpss.test(diff(diff(t_train)), null="Level")


kpss.test(t_train, null="Trend")
kpss.test(diff(t_train), null="Trend")
kpss.test(diff(diff(t_train)), null="Trend")
```
```{r}
acf(t_train)

acf(diff(t_train))

acf(diff(diff(t_train)))

```


By observing two plots, both of them seems stationary.       
Implement the KPSS test for three levels of data which are no differences, 1st difference, and 2nd difference. At the 1st and 2nd differences, the p-value is 0.1 for both level and trend KPSS test, so they failed to reject the null hypothesis. Thus, the 1st and 2nd differences data sets are stationary in both level and trend aspects.          
Comparing with 1st and 2nd difference, the p-value isn't improved by having one more difference. Also observing the ACF plots, the 1st differences data has exponential decay ACF. Thus, consider the 1st differences for this data set to avoid over-difference problem.



###  Question 4:
Fit a suitable ARIMA model to the training dataset using the auto.arima() function. Remember to transform the data first if necessary. Report the resulting p,d,q and the coefficients values.

```{r}

model_auto = auto.arima(t_train, d=1)
model_auto

model_auto$coef

```
p = 2, d = 1 and q = 0             
      ar1       ar2     drift            
0.2829272 0.1163398 0.1850590             
Form the last question, use 1st difference data set so set the d = 1.      


###  Question 5:
Compute the sample Extended ACF (EACF) and use the Arima() function to try some other plausible models by experimenting with the orders chosen. Limit your models to q,p <=2 and d <= 2. Use the model summary() function to compare the Corrected Akaike information criterion (i.e., AICc) values (Note: Smaller values indicated better models)

```{r}
eacf(diff(t_train), ar.max = 2, ma.max = 2)

model_02 = Arima(t_train, order = c(0,1,2), include.drift = TRUE)
summary(model_02)
model_12 = Arima(t_train, order = c(1,1,2), include.drift = TRUE)
summary(model_12)
model_22 = Arima(t_train, order = c(2,1,2), include.drift = TRUE)
summary(model_22)
```
From the EACF, we have three options which are AR = 0/1/2, MA = 2.
Try arima model for those three models with drift. 
c(0,1,2): AICc=-101.81       
c(1,1,2): AICc=-100.57       
c(2,1,2): AICc=-100.43       
Choose the samllest AICc, so the best AR is 0 and MA is 2.




###  Question 6:
Use the model chosen in Question 4 to forecast and plot the GDP forecasts with 80 and 95 % confidence levels for 2005Q2 - 2006Q1 (Test Period).
```{r}

pred = forecast(model_02, h = 4)
pred
plot(pred, include= 50)

```



###  Question 7:
Compare your forecasts with the actual values using error = actual - estimate and plot the errors. (Note: Use the forecast $mean element for the forecast estimate)
```{r}

t_pred <- InvBoxCox(pred$mean, lambda = lambda)
error <- test - t_pred
plot(error)

```



###  Question 8:
Calculate the sum of squared error.

```{r}
sum(error^2)
```
The SSE is 19743.02      

